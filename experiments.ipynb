{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c84b4e-f200-447b-ab24-4ccb6cbb525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.backend import ensembles as ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73897345-bdb0-4c0b-9859-f346e40f1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='paper', style='whitegrid', font_scale=2)\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'svg')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504354dd-35d7-4df0-afcc-2605918c5408",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c62e9-f04f-485f-99f1-26be7725bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kc_house_data.csv', parse_dates=['date']).drop('id', axis=1)\n",
    "data.date = pd.to_numeric(data.date)\n",
    "\n",
    "data, target = data.drop('price', axis=1).to_numpy(), data['price'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size=0.8, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6c886-ebaf-412f-a3f6-0f1894d24e9c",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda7c0e-d99f-457f-95aa-95987a12abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(2, 11)\n",
    "feature_subsample_sizes = np.linspace(0.1, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b27f7-b018-4018-8fc6-317eacf3fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_rf = {}\n",
    "\n",
    "for dpt in depths:\n",
    "    losses_rf[dpt] = {}\n",
    "    for ftr in feature_subsample_sizes:\n",
    "        model = ens.RandomForestMSE(n_estimators=100, max_depth=dpt, feature_subsample_size=ftr)\n",
    "        _, val_loss = model.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        losses_rf[dpt][ftr] = np.sqrt(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98240e-9a5d-4ebf-a3e0-59fef5dabdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rf = {}\n",
    "\n",
    "for i, dpt in enumerate(depths):\n",
    "    times_rf[dpt] = {}\n",
    "    for ftr in feature_subsample_sizes:\n",
    "        times_rf[dpt][ftr] = []\n",
    "        for n_est in range(5, 101, 5):\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            model = ens.RandomForestMSE(n_estimators=n_est, max_depth=dpt, feature_subsample_size=ftr)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            times_rf[dpt][ftr].append(time.perf_counter() - start_time)\n",
    "    print(f'iteration [{i + 1}/{len(depths)}] ended', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f4832-ac07-404c-add5-05ac7e0cfb9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(depths), len(feature_subsample_sizes), figsize=(15, 18), sharex=True, sharey='row')\n",
    "for i, ftr_sub_size in enumerate(feature_subsample_sizes):\n",
    "    for j, dpt in enumerate(depths):\n",
    "        ax[j][i].plot(losses_rf[dpt][ftr_sub_size])\n",
    "        if j == 0:\n",
    "            ax[j][i].set_title(f'ftr size = {ftr_sub_size}')\n",
    "        if i + 1 == len(feature_subsample_sizes):\n",
    "            ax[j][i].yaxis.set_label_position(\"right\")\n",
    "            ax[j][i].set_ylabel(f'depth = {dpt}')\n",
    "fig.supxlabel('iteration')\n",
    "fig.supylabel('loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f145ba-15b1-4832-bc6b-88af8c8c54fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(depths), len(feature_subsample_sizes), figsize=(15, 20), sharex=True, sharey='row')\n",
    "for i, ftr_sub_size in enumerate(feature_subsample_sizes):\n",
    "    for j, dpt in enumerate(depths):\n",
    "        ax[j][i].plot(times_rf[dpt][ftr_sub_size])\n",
    "        if j == 0:\n",
    "            ax[j][i].set_title(f'ftr size = {ftr_sub_size}')\n",
    "        if i + 1 == len(feature_subsample_sizes):\n",
    "            ax[j][i].yaxis.set_label_position(\"right\")\n",
    "            ax[j][i].set_ylabel(f'depth = {dpt}')\n",
    "plt.xticks(ticks=np.arange(0, len(times_rf_no_dpt[0.1]) + 1, 10), labels=np.linspace(5, 100, 3, dtype=int))\n",
    "fig.supxlabel('iterations')\n",
    "fig.supylabel('time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f8b93-9308-4026-b242-fa1b5608519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_rf_no_dpt = {}\n",
    "\n",
    "for ftr in feature_subsample_sizes:\n",
    "    model = ens.RandomForestMSE(n_estimators=100, max_depth=None, feature_subsample_size=ftr)\n",
    "    _, val_loss = model.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    losses_rf_no_dpt[ftr] = np.sqrt(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11241e-353b-45dc-8a2f-45d4e8071f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rf_no_dpt = {}\n",
    "\n",
    "for i, ftr in enumerate(feature_subsample_sizes):\n",
    "    iter_start = time.perf_counter()\n",
    "    times_rf_no_dpt[ftr] = []\n",
    "    for n_est in range(5, 101, 5):\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        model = ens.RandomForestMSE(n_estimators=n_est, max_depth=None, feature_subsample_size=ftr)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        times_rf_no_dpt[ftr].append(time.perf_counter() - start_time)\n",
    "    iter_time = time.perf_counter() - iter_start\n",
    "    print(f'iteration [{i + 1}/{len(feature_subsample_sizes)}] ended, time: {iter_time:.02f}', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed58ed-152b-41f0-826a-0f1f0f7cc8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for ftr in feature_subsample_sizes:\n",
    "    plt.plot(losses_rf_no_dpt[ftr], label=str(ftr)[:5])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07951cb4-7503-4c82-b232-a514c45940b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for ftr in feature_subsample_sizes:\n",
    "    plt.plot(times_rf_no_dpt[ftr][:-1], label=str(ftr)[:5])\n",
    "\n",
    "plt.xticks(ticks=np.arange(0, len(times_rf_no_dpt[0.1]), 2), labels=np.arange(5, 101, 10))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343039b6-a3aa-46b1-8f89-f1838c9622a5",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b191a-29a6-403b-90a7-c350ccf8b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = np.arange(2, 11)\n",
    "feature_subsample_sizes = np.linspace(0.1, 1, 5)\n",
    "lrs = [0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109797f-bc0b-43d9-b22b-69a948fdbd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_gb = {}\n",
    "\n",
    "for dpt in depths:\n",
    "    losses_gb[dpt] = {}\n",
    "    for ftr in feature_subsample_sizes:\n",
    "        losses_gb[dpt][ftr] = {}\n",
    "        for lr in lrs:\n",
    "            model = ens.GradientBoostingMSE(n_estimators=100, max_depth=dpt, feature_subsample_size=ftr, learning_rate=lr)\n",
    "            _, val_loss = model.fit(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "            losses_gb[dpt][ftr][lr] = np.sqrt(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7a141-ad47-4a1f-8284-56ebb1a1439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_gb = {}\n",
    "\n",
    "for i, dpt in enumerate(depths):\n",
    "    iter_start = time.perf_counter()\n",
    "    times_gb[dpt] = {}\n",
    "    for ftr in feature_subsample_sizes:\n",
    "        times_gb[dpt][ftr] = {}\n",
    "        for lr in lrs:\n",
    "            times_gb[dpt][ftr][lr] = []\n",
    "            for n_est in range(5, 101, 5):\n",
    "                start_time = time.perf_counter()\n",
    "    \n",
    "                model = ens.RandomForestMSE(n_estimators=n_est, max_depth=dpt, feature_subsample_size=ftr)\n",
    "                model.fit(X_train, y_train)\n",
    "    \n",
    "                times_gb[dpt][ftr][lr].append(time.perf_counter() - start_time)\n",
    "    iter_time = time.perf_counter() - iter_start\n",
    "    print(f'iteration [{i + 1}/{len(depths)}] ended, time: {iter_time:.02f}', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638c064-4892-4584-bc43-307adb9572a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(depths), len(feature_subsample_sizes), figsize=(15, 18), sharex=True, sharey='row')\n",
    "for i, ftr_sub_size in enumerate(feature_subsample_sizes):\n",
    "    for j, dpt in enumerate(depths):\n",
    "        for lr in lrs[:-1]:\n",
    "            ax[j][i].plot(losses_gb[dpt][ftr_sub_size][lr], label=str(lr)[:5])\n",
    "        if j == 0:\n",
    "            ax[j][i].set_title(f'ftr size = {ftr_sub_size}')\n",
    "        if i + 1 == len(feature_subsample_sizes):\n",
    "            ax[j][i].yaxis.set_label_position(\"right\")\n",
    "            ax[j][i].set_ylabel(f'depth = {dpt}')\n",
    "        handles, labels = ax[j][i].get_legend_handles_labels()\n",
    "fig.supxlabel('iteration')\n",
    "fig.supylabel('loss')\n",
    "fig.legend(handles, labels, loc='upper center', ncol=6, bbox_to_anchor=(0.5, 0), title='learning rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217ac62-c854-49e2-9f48-0e0cef805edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(depths), len(feature_subsample_sizes), figsize=(15, 18), sharex=True, sharey='row')\n",
    "for i, ftr_sub_size in enumerate(feature_subsample_sizes):\n",
    "    for j, dpt in enumerate(depths):\n",
    "        for lr in lrs[:-1]:\n",
    "            ax[j][i].plot(times_gb[dpt][ftr_sub_size][lr], label=str(lr)[:5])\n",
    "        if j == 0:\n",
    "            ax[j][i].set_title(f'ftr size = {ftr_sub_size}')\n",
    "        if i + 1 == len(feature_subsample_sizes):\n",
    "            ax[j][i].yaxis.set_label_position(\"right\")\n",
    "            ax[j][i].set_ylabel(f'depth = {dpt}')\n",
    "        handles, labels = ax[j][i].get_legend_handles_labels()\n",
    "plt.xticks(ticks=np.arange(0, 21, 10), labels=np.linspace(5, 100, 3, dtype=int))\n",
    "fig.supxlabel('iteration')\n",
    "fig.supylabel('time (s)')\n",
    "fig.legend(handles, labels, loc='upper center', ncol=6, bbox_to_anchor=(0.5, 0), title='learning rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c1ecd-c202-4471-99a8-b415c24d1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_gb_no_dpt = {}\n",
    "\n",
    "for ftr in feature_subsample_sizes:\n",
    "    losses_gb_no_dpt[ftr] = {}\n",
    "    for lr in lrs:\n",
    "        model = ens.GradientBoostingMSE(n_estimators=50, max_depth=100, feature_subsample_size=ftr, learning_rate=lr)\n",
    "        _, val_loss = model.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        losses_gb_no_dpt[ftr][lr] = np.sqrt(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a334bae-1f13-4770-8f73-82a958f1af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_gb_no_dpt = {}\n",
    "\n",
    "for i, ftr in enumerate(feature_subsample_sizes):\n",
    "    times_gb_no_dpt[ftr] = {}\n",
    "    for lr in lrs:\n",
    "        times_gb_no_dpt[ftr][lr] = []\n",
    "        for n_est in range(5, 51, 5):\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            model = ens.GradientBoostingMSE(n_estimators=n_est, max_depth=100, feature_subsample_size=ftr, learning_rate=lr)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            times_gb_no_dpt[ftr][lr].append(time.perf_counter() - start_time)\n",
    "    print(f'iteration [{i + 1}/{len(feature_subsample_sizes)}] ended', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b4b9a-8a33-4526-a9d5-18a9c4c771f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(lrs) - 1, len(feature_subsample_sizes), figsize=(12, 8), sharex=True, sharey='row')\n",
    "for i, ftr_sub_size in enumerate(feature_subsample_sizes):\n",
    "    for j, lr in enumerate(lrs[:-1]):\n",
    "        ax[j][i].plot(losses_gb_no_dpt[ftr_sub_size][lr])\n",
    "        if j == 0:\n",
    "            ax[j][i].set_title(f'ftr size = {ftr_sub_size}')\n",
    "        if i + 1 == len(feature_subsample_sizes):\n",
    "            ax[j][i].yaxis.set_label_position(\"right\")\n",
    "            ax[j][i].set_ylabel(f'lr = {lr}')\n",
    "fig.supxlabel('iteration')\n",
    "fig.supylabel('loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d31e6a-db05-4f85-81d8-3f485c9d20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(lrs), len(feature_subsample_sizes), figsize=(12, 8), sharex=True, sharey='row')\n",
    "for i, ftr_sub_size in enumerate(feature_subsample_sizes):\n",
    "    for j, lr in enumerate(lrs):\n",
    "        ax[j][i].plot(times_gb_no_dpt[ftr_sub_size][lr])\n",
    "        if j == 0:\n",
    "            ax[j][i].set_title(f'ftr size = {ftr_sub_size}')\n",
    "        if i + 1 == len(feature_subsample_sizes):\n",
    "            ax[j][i].yaxis.set_label_position(\"right\")\n",
    "            ax[j][i].set_ylabel(f'lr = {lr}')\n",
    "plt.xticks(ticks=np.arange(0, 11, 10), labels=np.linspace(5, 50, 2, dtype=int))\n",
    "fig.supxlabel('iterations')\n",
    "fig.supylabel('time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
